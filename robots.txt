# robots.txt for mahamadsekh61-bot.github.io
# Last updated: October 20, 2025

# Allow all search engines to crawl everything
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://mahamadsekh61-bot.github.io/sitemap.xml

# Crawl delay (be nice to servers)
Crawl-delay: 1

# Specific directives for major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block access to sensitive files (none in our case, but good practice)
Disallow: /.git/
Disallow: /*.json$
Disallow: /README.md
